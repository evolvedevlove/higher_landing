{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a code break down for the land_scrape.py script located in this repository. For further context, please see my LinkedIn article https://www.linkedin.com/pulse/i-made-web-bot-instead-doing-my-homework-patrick-crosman and the accompanying Youtube video https://youtu.be/e7rZ24X8osA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this code break down is to be descriptive and accessible to any reader. If you are a tech nerd and you see a glaring issue in the way I have architected this solution, please make a pull request or reach and let me know. (email address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' There are a whole bunch of handy features from Selenium needed to drive our browser and control the pace of execution. '''\n",
    "from selenium import webdriver as wd\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of readibility in this breakdown, I will import libraries as they are used. Let's open up a browser and move it to the side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'height': 1100, 'width': 1200, 'x': 930, 'y': 0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' open a new chrome browser using the webdriver service '''\n",
    "chromedriver_service = Service('./chromedriver.exe')\n",
    "browser = wd.Chrome(service=chromedriver_service)\n",
    "browser.set_window_rect(x=930, y=0, width=1200, height=1125) # this is specific to my monitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a browser, we could go the events page on the Higher Landing website. For the sake of security, I have stored all credentials and sensitive information into a JSON file. Loading this JSON into a Python dictionary object allows us to use key/value pairs to access private data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['base_path', 'user_name', 'user_password', 'required_sessions_file', 'events_url', 'locators'])\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "''' get secret test information from a json file '''\n",
    "base_path = r\"H:\\2021-11-03-HIGHER-LANDING\\\\\"\n",
    "test_info_file_name = 'secret_test_info.json'\n",
    "with open(base_path + './' + test_info_file_name, 'r') as t_f:\n",
    "    json_string = t_f.read()\n",
    "test_info_dict = json.loads(json_string)\n",
    "print(test_info_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The keys listed above will be used for data access and field location. Below, we __get__ the value of the events url from our test info dictionary and then use the browser's __get__ function to load the url. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' open the browser to the events page of the course '''\n",
    "url = test_info_dict.get('events_url')\n",
    "browser.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will take us to the log in page, but it is good practice to make the browser wait until everything is loaded. The WebdriverWait module is used to achieve this. Let's wait until the Log In button is ready to click. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' wait until we can click on the log in button'''\n",
    "waiter = WebDriverWait(browser, 10)\n",
    "ready_for_input = waiter.until(EC.element_to_be_clickable((\n",
    "    By.ID, test_info_dict.get('locators').get('login_submit_button'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The By.ID selector is used multiple times here in conjunction with the locators from our test info dictionary. Selenium's find element function returns an html element that can be interacted with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' enter the user name and password by using locators, all data is stored in test_info_dict '''\n",
    "user_name_field = browser.find_element(By.ID, test_info_dict.get('locators').get('user_name_field'))\n",
    "user_name_field.send_keys(test_info_dict.get('user_name'))\n",
    "user_password_field = browser.find_element(By.ID, test_info_dict.get('locators').get('user_pass_field'))\n",
    "user_password_field.send_keys(test_info_dict.get('user_password'))\n",
    "\n",
    "''' locate the login button and click it '''\n",
    "login_button = browser.find_element(By.ID, test_info_dict.get('locators').get('login_submit_button'))\n",
    "login_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we directly loaded the event page url, we will wait for the Upcoming Events link to be ready before clicking it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' wait until the Upcoming Events link is ready to be clicked '''\n",
    "upcoming_events_locator = test_info_dict.get('locators').get('upcoming_events_link')\n",
    "calendar_ready = waiter.until(EC.element_to_be_clickable((By.ID, upcoming_events_locator)))\n",
    "upcoming_events_link = browser.find_element(By.ID, upcoming_events_locator)\n",
    "upcoming_events_link.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each event is listed with a truncated description and an RSVP button. We will wait until the first RSVP button is ready to be clicked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' wait until the first rsvp button is ready to be clicked '''\n",
    "first_rsvp_button_locator = test_info_dict.get('locators').get('first_rsvp_button')\n",
    "upcoming_events_page_ready = waiter.until(EC.element_to_be_clickable((By.ID, first_rsvp_button_locator)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will grab all of the link titles using a regular expression and BeautifulSoup's find_all function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "''' use the html parser from BeautifulSoup to find all the links matching a specific pattern  '''\n",
    "page_soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "event_title_regex_pattern = test_info_dict.get('locators').get('event_title_links_regex')\n",
    "event_title_links = page_soup.find_all(\"a\", {\"id\": re.compile(event_title_regex_pattern)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare the link text to the required sessions and determine which events to attend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' read the contents of the required sessions file into string for easy comparison '''\n",
    "required_sessions_file = open(r\"H:\\2021-11-03-HIGHER-LANDING\\schedule.txt\", \"r\")\n",
    "required_sessions_string = required_sessions_file.read()\n",
    "\n",
    "''' an empty list which will be populated in the for loop below '''\n",
    "events_to_attend_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next chunk of code is more suited to be modularized into three separate functions, but since you have come this far already, let's just work through in the comments below. We will go through every link and grab the event time, zoom link, and description from the event details page. I have also created this script in a modular format. (link here to modular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to Pitch Yourself\n",
      "skipped Appreciative Inquiry Clinic\n",
      "skipped Resume Clinic\n",
      "skipped Marketing Club\n",
      "skipped Branding Clinic\n",
      "skipped LinkedIn Clinic\n",
      "Interview Preparation\n",
      "Market Yourself Like a Pro Part I\n",
      "Resume Writing Studio Part II\n",
      "skipped Pitch Clinic\n",
      "skipped Grizzly Research Clinic\n",
      "Art of Blogging\n",
      "skipped Knowing Your Brand I\n",
      "skipped Marketing Club\n",
      "skipped Interview Clinic\n",
      "Higher Landing Grizzly Den\n",
      "skipped Knowing Your Brand II\n",
      "Higher Landing Grizzly Den\n",
      "Emerging Sectors & Transferable Skills\n",
      "skipped IP Clinic\n",
      "skipped Resume Writing Studio I\n",
      "skipped G2M Finalization Meeting\n",
      "skipped Transferable Skills & Values Clinic\n",
      "skipped Branding Clinic\n",
      "Market Yourself Like a Pro II\n",
      "Promoting Your Brand on LinkedIn\n",
      "skipped Resume Clinic\n",
      "How to Pitch Yourself\n",
      "skipped Appreciative Inquiry Clinic\n",
      "skipped Resume Writing Studio II\n"
     ]
    }
   ],
   "source": [
    "''' go through all the events on the page and gather the event start time and details '''\n",
    "for link in event_title_links:\n",
    "    if link.text in required_sessions_string:\n",
    "        ''' link.text, event_time, zoom_link, description  '''\n",
    "        print(link.text)\n",
    "        ''' use the id property from the current link to enter the event details page '''\n",
    "        click_me = browser.find_element(By.ID, link['id'])\n",
    "        click_me.click()\n",
    "        rsvp_page_ready = waiter.until(EC.element_to_be_clickable((\n",
    "            By.ID, test_info_dict.get('locators').get('event_rsvp_button'))))\n",
    "        \n",
    "        ''' parse the current page and search for the zoom link '''\n",
    "        tmp_event_soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "        zoom_link = tmp_event_soup.find('p', text=re.compile('^https:.*zoom'))\n",
    "        \n",
    "        ''' get the parent/containing element '''\n",
    "        if zoom_link is not None:\n",
    "            description_container_element = zoom_link.parent\n",
    "            zoom_link_text = zoom_link.text\n",
    "        else:\n",
    "            # in the case where our first attempt did not locate the zoom link directly\n",
    "            description_container_element = tmp_event_soup.find(class_='column wpc65 left')\n",
    "            zoom_link_text = description_container_element.text.split('via Zoom:')[1]\n",
    "\n",
    "        ''' this is not perfect currently pulling out too many spaces '''\n",
    "        description_text = description_container_element.text.split('Send calendar to email')[1].replace(u'\\n', ' ')\n",
    "\n",
    "        ''' collect the start time, date, and full event description '''\n",
    "        event_start_datetime_locator = test_info_dict.get('locators').get('event_start_datetime')\n",
    "        event_start_datetime = description_container_element.find(id=event_start_datetime_locator)\n",
    "        event_start_datetime_formatted = event_start_datetime.text.replace('/', '-')\n",
    "        \n",
    "        ''' create a tuple to add to the events to attend list '''\n",
    "        tmp_tuple = (link.text, event_start_datetime_formatted, zoom_link_text, description_text.replace(u'\\xa0', ' '))\n",
    "        #print(str(tmp_tuple))\n",
    "        events_to_attend_list.append(tmp_tuple)\n",
    "        \n",
    "        ''' navigate back to previous page '''\n",
    "        back_to_calendar_link = browser.find_element(By.ID, test_info_dict.get('locators').get('back_calendar_link'))\n",
    "        back_to_calendar_link.click()\n",
    "        tmp_calendar_ready = waiter.until(EC.element_to_be_clickable((By.ID, upcoming_events_locator)))\n",
    "        tmp_upcoming_events_link = browser.find_element(By.ID, upcoming_events_locator)\n",
    "        tmp_upcoming_events_link.click()\n",
    "        tmp_upcoming_events_page_ready = waiter.until(EC.element_to_be_clickable((By.ID, first_rsvp_button_locator)))\n",
    "    else:\n",
    "        print(\"skipped {}\".format(link.text))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so now we have a list of the details for the required events, let's quickly use Pandas to output a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "''' use the events to attend list to create a pandas dataframe '''\n",
    "events_to_attend_df = pd.DataFrame(events_to_attend_list, columns=[\"Title\", \"Start Time\", \"Link\", \"Description\"])\n",
    "events_to_attend_df.to_csv(\"{}-Required_Events.csv\".format(base_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next logical step here would be to use the Google Calendar API to create events, or really, anything. Thank you for your time! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
